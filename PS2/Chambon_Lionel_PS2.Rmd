---
title: "Econometrics III - PS 2"
author: "Lionel Chambon"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tidyverse)
library(haven)
library(sandwich)
library(lmtest)
library(fixest)
library(glue)

setwd("/Users/lionelchambon/Desktop/LIONEL/LIONEL_edu/MASTER/M2/Cours/Econometrics III/Problem Sets/PS2")

```

## Exercise 1


### Background

108 schools were selected. The two first grades were either formed based on ability (tracking group) or randomly (non-tracking group).

### Question 1

```{r}

tracking_data <- read_dta("tracking.dta")
summary(tracking_data)
head(tracking_data)

```

First, we aggregate the data onto the school level.

```{r}

school_level_data <- tracking_data %>%
  group_by(schoolid) %>%
  summarize(
    mean_grades = mean(scoreendfirstgrade, na.rm = TRUE),                  
    treated = mean(tracking, na.rm = TRUE),               
    below_median = mean(bottomhalf, na.rm = TRUE),      
    n_students = n()                                         
  )

head(school_level_data)

```

Now, I choose to run a linear regression to estimate the treatment effect.

```{r}

reg_q1 <- lm(mean_grades ~ treated, data = school_level_data)
summary(reg_q1)

reg_q1_c <- lm(mean_grades ~ treated + below_median, data = school_level_data)
summary(reg_q1_c)

```

This first analysis tells us that on average, students in tracked schools are 
predicted to have higher grades of ~0.13 (standardized) points. We can also see
that students in the bottom half are expected to have a 
higher grade on average, but this effect is not statistically significant. 
The positive effect of tracking is about the same even when not controlling 
for the \textit{bottomhalf} variable.

We see that the result does not change by much in magnitude if we use the 
unmodified data:

```{r}
reg_q1_b <- lm(scoreendfirstgrade ~ tracking, data = tracking_data)
summary(reg_q1)

reg_q1_c_b <- lm(scoreendfirstgrade ~ tracking + bottomhalf, data = tracking_data)
summary(reg_q1_c)

```

### Question 2

A randomized inference test investigates $H_0: \beta_1 = 0$. To do so, we would like to "shuffle" the treatment randomly across observations. Then, we recompute a null distribution of coefficients and then determine whether or not to reject $H_0$. First, we need to aggregate data by each school:

```{r}

observed_coef <- coef(reg_q1)["treated"]

perm <- 1000

permuted_coef <- numeric(perm)

for (i in 1:perm) {
  shuffled <- sample(school_level_data$treated)
  
  permuted_reg <- lm(mean_grades ~ shuffled, data = school_level_data)
  
  permuted_coef[i] <- coef(permuted_reg)["shuffled"]
}

conf_interval <- quantile(permuted_coef, probs = c(0.05, 0.95))

if (observed_coef < conf_interval[1] | observed_coef > conf_interval[2]) {
  print("We can reject the null hypothesis")
} else {
  print("We fail to reject the null hypothesis.")
}            

```

We narrowly reject $H_0$

### Question 3

One idea could be to investigate this using an interaction term with the \textit{bottomhalf} variable:

```{r}

reg_q1_c_i <- lm(mean_grades ~ treated + below_median + (treated*below_median), data = school_level_data)

summary(reg_q1_c_i)

```

The coefficient of the interaction term reveals that the effect is reduced
for below-median performing students, although the coefficient is not 
significant at $\alpha = 10\%$. 

## Question 2

### Question 1

### Question 2

```{r}

n=1000
v = rnorm(n, 0,1)
y_0 = rnorm(n, 0,1)
y_1 = 0.5*y_0 + 0.5*v + 0.2

sim_data <- data.frame(y_0 = y_0, y_1 = y_1)

head(sim_data)

```

### Question 3

I would expect the treatment effect to be heteregenous. If we compute the
treatment effect as the difference between $y_0$ and $y_1$, we have
$0.5*y_0 - 0.5*v - 0.2$. $y_0$ and $V$ are both independent random
normal variables, so the realizations will vary across units.

### Question 4

```{r}

sim_data = sim_data %>%
  mutate(te = y_1 - y_0)

ate = sim_data %>%
  summarise(mean(te))

print(ate)

```

### Question 5

```{r}

cor = cor(y_0, y_1)
var = var(sim_data$te)

print(cor)
print(var)

```

### Question 6

```{r}

iterations = 800

results = data.frame(
  ATE = numeric(iterations),
  Variance = numeric(iterations),
  Confidence_Inclusion = integer(iterations)
)

for (i in 1:iterations) {

  random_sort = runif(n)
  
  sim_data_sorted = sim_data %>% 
    mutate(random_sort)
  
  sim_data_sorted = sim_data_sorted %>%
    arrange(random_sort)
  
  sim_data_sorted = sim_data_sorted %>%
    mutate(D = ifelse(row_number() <= 500, 1, 0)) %>%
    mutate(Y = (1 - D) * y_0 + D * y_1)
  
  reg_q2 = feols(Y ~ D, se = "hetero", data = sim_data_sorted)
  
  ate_hat = coef(reg_q2)["D"]
  var_hat = se(reg_q2)["D"]^2
  
  # if (ate == coef(reg_q2)) {
  #  print(TRUE)
  # } else {
  #   print(FALSE)
  # }
  
  # if (var == var_hat) {
  #   print(TRUE)
  # } else {
  #   print(FALSE)
  # }
  
  ci_lower = ate_hat - 1.96 * sqrt(var_hat)
  ci_upper = ate_hat + 1.96 * sqrt(var_hat)
  
  indicator = as.numeric(ate >= ci_lower & ate <= ci_upper)
  
  results[i, ] = c(ate_hat, var_hat, indicator)

}

```

I used this code that is in comment mode above to check whether $ate$ and 
$var_hat$ were equal to the previous result. I commented it to avoid having 
a long list as output on the document. In short, the values are never equal.

````{r}    

mean_ate_hat = mean(results$ATE)

result_ate <- glue("The mean of the estimates is {mean_ate_hat}, the true value is {ate}.")
print(result_ate)

var_ate_hat <- var(results$ATE)
mean_var_hat <- mean(var_ate_hat)
result_var <- glue("The mean of the variace is {mean_var_hat}, the true value is {var}.")
print(result_var)


coverage_probability = mean(results$Confidence_Inclusion)
print(coverage_probability)

```

Interpretation here.

### Question 7

```{r}

iterations = 800

results_2 = data.frame(
  ATE = numeric(iterations),
  Variance = numeric(iterations),
  Confidence_Inclusion = integer(iterations)
)

for (i in 1:iterations) {

  random_sort_2 = runif(n)
  
  sim_data_sorted_2 = sim_data %>% 
    mutate(random_sort_2)
  
  sim_data_sorted_2 = sim_data_sorted_2 %>%
    arrange(random_sort_2)
  
  sim_data_sorted_2 = sim_data_sorted_2 %>%
    mutate(D_2 = ifelse(row_number() <= 500, 1, 0)) %>%
    mutate(Y_2 = (1 - D_2) * y_0 + D_2 * y_1)
  
  reg_q2_2 = feols(Y_2 ~ D_2, se = "hetero", data = sim_data_sorted_2)
  
  ate_hat_2 = coef(reg_q2_2)["D_2"]
  var_hat_2 = se(reg_q2_2)["D_2"]^2
  
  # if (ate == coef(reg_q2_2)) {
  #  print(TRUE)
  # } else {
  #   print(FALSE)
  # }
  
  # if (var == var(var_hat_2) {
  #   print(TRUE)
  # } else {
  #   print(FALSE)
  # }
  
  ci_lower_2 = ate_hat_2 - 1.96 * sqrt(var_hat_2)
  ci_upper_2 = ate_hat_2 + 1.96 * sqrt(var_hat_2)
  
  indicator_2 = as.numeric(0.2 >= ci_lower_2 & ate <= ci_upper_2)
  
  results_2[i, ] = c(ate_hat_2, var_hat, indicator_2)

}
  
```

Finally:

````{r}    

mean_ate_hat_2 = mean(results_2$ATE)

result_ate_2 <- glue("The mean of the estimates is {mean_ate_hat}, the true value is {ate}.")
print(result_ate_2)

var_ate_hat_2 <- var(results_2$ATE)
mean_var_hat_2 <- mean(var_ate_hat_2)
result_var_2 <- glue("The mean of the variace is {mean_var_hat}, the true value is {var}.")
print(result_var_2)


coverage_probability_2 = mean(results_2$Confidence_Inclusion)
print(coverage_probability_2)

```

Interpretation here.